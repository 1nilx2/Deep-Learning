# Statistics

## Cross-entropy & KL Divergence
Entropy is average amount of information and can be said degree of surprise

for discrete r.v. x,

$$ H[x] = -\sum{x}$$
