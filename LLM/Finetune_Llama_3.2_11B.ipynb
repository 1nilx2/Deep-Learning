{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af21ebfB84Jc"
      },
      "source": [
        "# Notebook\n",
        "This notebook was tested on Google Colab.\n",
        "Data Preparation, fine-tuning, and Inference will be done with Llama 3.2 11B, which has vision capability. Code base refers to other public sources which were devised to have flextibility to be used for other models also as long as you adjust parameters and components according to the models.\n",
        "\n",
        "Test was done with A100 GPU\n",
        "\n",
        "[Reference1](https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/fine-tune-multimodal-llms-with-trl.ipynb), [Reference2](https://github.com/huggingface/huggingface-llama-recipes/blob/main/fine_tune/Llama-Vision%20FT.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaH437QWb-9f"
      },
      "outputs": [],
      "source": [
        "%pip install tensorboard pillow\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "%pip install  --upgrade \\\n",
        "  \"transformers==4.45.1\" \\\n",
        "  \"datasets==3.0.1\" \\\n",
        "  \"accelerate==0.34.2\" \\\n",
        "  \"evaluate==0.4.3\" \\\n",
        "  \"bitsandbytes==0.44.0\" \\\n",
        "  \"trl==0.11.1\" \\\n",
        "  \"peft==0.13.0\" \\\n",
        "  \"qwen-vl-utils\"\n",
        "\n",
        "# According to colab version, you'd need to install `torchvision` again\n",
        "# %pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yl7MR3_PgYT"
      },
      "source": [
        "# Model\n",
        " you need to get access first. Visit the page in HuggingFace and see if you have an authority for the model.\n",
        " For Llama 3.2 11B and 90B, [visit here](https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct)\n",
        "\n",
        " Due to limited GPU Availability and Great performance light-weighted model can extract, We will use quantized model. Also with small number of datapoint, full fine-tuning can lead us to overfitting. So I'm going to use LoRA, which tries to approximate what would've been done by FFT using rather small number of parameters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRqrhwaPya4b",
        "outputId": "617cfdbc-4589-4ca5-8fea-49221d7cd59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login()  # USE YOUR TOKEN HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "89301a8501a4449393e152705cf9e6ee",
            "81ff1f3c895d4f4db682490ad47f7cb5",
            "c0544f709a26484eb74b9f5bd4ccb24b",
            "8f2adc73df734193bc43cf087c6d5a11",
            "67ecbf442e3848919d5833bba8399cdd",
            "f00fb44cfba84875a93213c8a8d95556",
            "f5374a39cb784bda8cacbebfa8bdfd04",
            "bf8248f1125f4bd19ffa0bebba00d24b",
            "81aa9173adc74e289d8b32cabb93b3c0",
            "41d2e4cc549b498ca10558c05efb3479",
            "52021f0505494de7b4eeb04c0c314d46"
          ]
        },
        "id": "qY8rVXEd9Rx0",
        "outputId": "090f02f1-35bf-4313-e079-a11477244af0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:accelerate.utils.modeling:The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89301a8501a4449393e152705cf9e6ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import MllamaForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
        "\n",
        "# Configuration for quantizing model into 4bit normal float (nf4)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=False,  # Additional quantization applied to quantization constant, but I don't want it now for better performance\n",
        ")\n",
        "\n",
        "# Load model and processor\n",
        "model = MllamaForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config,\n",
        "    # attn_implementation=\"flash_attention_2\", # not supported for training\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIQPwDGjCWvv"
      },
      "source": [
        "## Dataset\n",
        "We'd like to see dataset has three items: Query, Image, and Answer. \n",
        " - Query, if exists in an appropriate format, can be converted to the format model was trained for\n",
        " - Image is PIL object\n",
        " - Answer is a set of ground truths for which difference from model prediction will be calculated as a loss (Cross Entropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "C_gT1Bf5G8bH"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset from the hub\n",
        "dataset_id = \"philschmid/amazon-product-descriptions-vlm\"\n",
        "dataset = load_dataset(\"philschmid/amazon-product-descriptions-vlm\", split=\"train[:150]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to combine information from various columns of dataset above into a chatting template. \n",
        "Even though there can be slight variance, chat templates are used to consist of `role` and `content`. Sometimes `role` can be system, user, and assistant, but we won't include system here. Also you'd notice that **image is not provided here**. Images will be provided later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_Trh2jDVGvjG"
      },
      "outputs": [],
      "source": [
        "# Add a column where query for Llama will be located\n",
        "def add_text_feature(sample):\n",
        "\n",
        "    # note the image is not provided in the prompt its included as part of the \"processor\"\n",
        "    prompt= \"\"\"You are an expert product description writer for Amazon. Create a Short Product description based on the provided ##PRODUCT NAME## and ##CATEGORY## and image.\n",
        "    Only return description. The description should be SEO optimized and for a better mobile search experience.\n",
        "\n",
        "    ##PRODUCT NAME##: {product_name}\n",
        "    ##CATEGORY##: {category}\"\"\"\n",
        "\n",
        "    text = [{\"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\",},\n",
        "                {\"type\": \"text\", \"text\": prompt.format(product_name=sample[\"Product Name\"], category=sample[\"Category\"]),}\n",
        "                ]},\n",
        "            {\"role\": \"assistant\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": sample[\"description\"]}]}\n",
        "            ]\n",
        "    sample['text'] = text\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "03602f7401e74b0f8bb177a3167d724e",
            "18b3b78c8d1948c7a34ac1a4212b8e87",
            "cdef947871894923a7f4d0464e01079b",
            "d4e7729fe36a461f802b32c329baea9f",
            "10b8946335a54d728385ff5292d5e1a4",
            "7ba218e171844b6a8c83510d62d161ed",
            "9743b2439cca4c5c834f367b03bcc1fe",
            "84b6782254a840b3b41fbe788990e128",
            "9b0a64789798406fb07023011075468e",
            "d15c1993c827494091c8a767c7fc44a2",
            "eddd0b9ff2ca41ddb1b090fd5a61a3b5"
          ]
        },
        "id": "XD3QlZutIN1T",
        "outputId": "51f6cf20-16eb-432a-be03-b7aea30a175c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03602f7401e74b0f8bb177a3167d724e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Add a column which will contain every information as `query`\n",
        "dataset = dataset.map(add_text_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IRRbjP_4KMhI"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into train and test sets\n",
        "split_dataset = dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "# Access the train and test splits\n",
        "train_dataset = split_dataset['train']\n",
        "eval_dataset = split_dataset['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trainer will refer to the `collate_fn` to process our dataset. It basically does \n",
        " - make sure query, image, and answer follow appropriate format\n",
        " - convert those to vectors\n",
        " - specify components to be ignored during loss calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kXrIGM7dCepj"
      },
      "outputs": [],
      "source": [
        "def collate_fn(examples):\n",
        "\n",
        "    texts = [processor.apply_chat_template(example[\"text\"], tokenize=False) for example in examples]\n",
        "    images = [example[\"image\"] for example in examples]\n",
        "\n",
        "    # Tokenize the texts and process the images\n",
        "    batch = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    # The labels are the input_ids, and we mask the padding tokens in the loss computation\n",
        "    labels = batch[\"input_ids\"].clone()\n",
        "    labels[labels == processor.tokenizer.pad_token_id] = -100  #\n",
        "    # Ignore the image token index in the loss computation (model specific)\n",
        "    image_token_id = processor.tokenizer.convert_tokens_to_ids(processor.image_token)\n",
        "    labels[labels == image_token_id] = -100\n",
        "    batch[\"labels\"] = labels\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reefy8xZJSPq"
      },
      "source": [
        "## Trainer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9SATc0f90SB"
      },
      "source": [
        "The `SFTTrainer`  supports a native integration with `peft`, which makes it super easy to efficiently tune LLMs using, e.g. QLoRA. We only need to create our `LoraConfig` and provide it to the trainer. Our `LoraConfig` parameters are defined based on the [qlora paper](https://arxiv.org/pdf/2305.14314.pdf) and sebastian's [blog post](https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EgSX_k4F9xie",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "# LoRA config based on QLoRA paper & Sebastian Raschka experiment\n",
        "peft_config = LoraConfig(\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.05,\n",
        "        r=8,\n",
        "        bias=\"none\",\n",
        "        target_modules=[\"q_proj\", \"v_proj\"],\n",
        "        task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook is of an illustrative purpose so I will run it for only 1 epoch.\n",
        "How to calculate validation error if so? We can change the frequency by which validation loss will be calculated by stating `eval_strategy=\"steps\"`. The cell below indicates how to check the number of steps per training epoch. For our scenario, batch size and gradient accumulation step will affect. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dy-keXHMPnu",
        "outputId": "b867a257-4900-4a74-f94b-1208632a1273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Step per Epoch: 7\n"
          ]
        }
      ],
      "source": [
        "grad_acc_step = 8\n",
        "train_batch_size = 2\n",
        "num_train_steps = ( len(train_dataset) // grad_acc_step ) // train_batch_size\n",
        "print(f\"Training Step per Epoch: {num_train_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Beju2yWPJUjm"
      },
      "outputs": [],
      "source": [
        "from trl import (\n",
        "    ModelConfig,\n",
        "    SFTConfig,\n",
        "    SFTTrainer\n",
        ")\n",
        "args = SFTConfig(\n",
        "    num_train_epochs=1,\n",
        "    max_seq_length=1024,  # Adjust according to the length of training text\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=3,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=3,\n",
        "    output_dir=\"llama-32-11B-ft\",\n",
        "    per_device_eval_batch_size=1,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,  # conduct parameter update after stacking this number of forward pass\n",
        "    gradient_checkpointing=True,    # Strategically save/forget some results (activations)\n",
        "    gradient_checkpointing_kwargs={'use_reentrant': False},\n",
        "    remove_unused_columns=False,\n",
        "    dataset_kwargs={'skip_prepare_dataset': True},\n",
        "    bf16=True,\n",
        "    do_eval=True,\n",
        "    report_to=\"none\",\n",
        "    dataloader_pin_memory=False,\n",
        "\n",
        "    # log_level='info',\n",
        "    # prediction_loss_only=False,\n",
        "    label_names=[\"labels\"],  # To show validation error\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VNpClvxDJ6AM"
      },
      "outputs": [],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    peft_config=peft_config,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=collate_fn,\n",
        "    tokenizer=processor.tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "ypYM1uCPJ6D2",
        "outputId": "a92bcaa8-882f-4457-c17a-aba0dcd9ddfe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 05:45, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.182800</td>\n",
              "      <td>2.962725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.102700</td>\n",
              "      <td>2.943371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7, training_loss=3.1274712766919817, metrics={'train_runtime': 413.3045, 'train_samples_per_second': 0.29, 'train_steps_per_second': 0.017, 'total_flos': 1178027987631864.0, 'train_loss': 3.1274712766919817, 'epoch': 0.9333333333333333})"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We limited num training dataset to 120 for illustrative purpose\n",
        "# You might see better convergence with more data and epochs.\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will just save LoRA Adapter, which was trained with less than 1% of entire parameters. If you want to combine base model and LoRA adapter to make a standalone model, search for `unload_and_merge()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5ZJOkvgiJ6HY"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(args.output_dir)  # save LoRA adapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "uKC-cOs1PXLj"
      },
      "outputs": [],
      "source": [
        "# Clear memory\n",
        "\n",
        "del model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0dejKj_RJ-n"
      },
      "source": [
        "## Inference with trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "9e0af3471f0d40b4a9f8ebcb47435b8c",
            "3ecb30b81fde4093aa38669e76bbc022",
            "ced5b125d7054502b042ac2345110547",
            "a7418715e53148cba2a5c871295ba3d8",
            "a23e0c5078494bf7859287c52bca1cd0",
            "10de585a04494528b43d9e8a0fd88a22",
            "8fd94f4811d54cd1a22c8d8a219360e0",
            "c86df59720e64eec91d36da1497ed542",
            "c55b43df657c4d63abdeee1fed5d2e60",
            "f8c08d0b77704ac0b6019cf8f2438281",
            "0c74ef72161d4d24a22f4c1ce251c209"
          ]
        },
        "id": "B6bepU9IQM_x",
        "outputId": "b4b455f5-786b-47dc-b3ff-36eec84b111a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.utils.modeling:The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e0af3471f0d40b4a9f8ebcb47435b8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import MllamaForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
        "\n",
        "# Load model and tokenizer\n",
        "# quantization_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True, bnb_4bit_use_double_quant=False, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        "#     )\n",
        "model = MllamaForConditionalGeneration.from_pretrained(\n",
        "    model_id, device_map=\"auto\", torch_dtype=torch.bfloat16\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-6K-gAJUM_f"
      },
      "source": [
        "### Wrap the base model with adapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TyOlNJWFRBbB"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel\n",
        "adapter_path = '/content/my-awesome-llama/checkpoint-7'\n",
        "peft_model = PeftModel.from_pretrained(model, adapter_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "fBg6hKxJUXDJ"
      },
      "outputs": [],
      "source": [
        "def infer_fn(example):\n",
        "\n",
        "    # Change plain text into dictionary to be processed by processor\n",
        "    prompt= \"\"\"You are an expert product description writer for Amazon. Create a Short Product description based on the provided ##PRODUCT NAME## and ##CATEGORY## and image.\n",
        "    Only return description. The description should be SEO optimized and for a better mobile search experience.\n",
        "\n",
        "    ##PRODUCT NAME##: {product_name}\n",
        "    ##CATEGORY##: {category}\"\"\"\n",
        "\n",
        "    text = [{\"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\",},\n",
        "                {\"type\": \"text\", \"text\": prompt.format(product_name=sample[\"Product Name\"], category=sample[\"Category\"]),}\n",
        "                ]}\n",
        "            ]\n",
        "\n",
        "    texts = [processor.apply_chat_template(text, add_generation_prompt=True)]\n",
        "    images = [example[\"image\"]]\n",
        "\n",
        "    # Tokenize the texts and process the images\n",
        "    inputs = processor(text=texts, images=images, return_tensors=\"pt\", padding=True, add_special_tokens=False).to(peft_model.device)\n",
        "\n",
        "    # Make an inference\n",
        "    with torch.no_grad():\n",
        "            output = peft_model.generate(**inputs, max_new_tokens=300)\n",
        "\n",
        "    return processor.decode(output[0][inputs[\"input_ids\"].shape[-1]:])  # exclude input query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "BM7v7TBhWSqx"
      },
      "outputs": [],
      "source": [
        "output = infer_fn(eval_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "EQrDjlj1XAlF",
        "outputId": "c3eaa227-78e1-419e-acc1-cab8b0c6212b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'**Unleash Your Inner Historian with Springbok Puzzles\\' Americana 500-Piece Jigsaw Puzzle**\\n\\nImmerse yourself in the rich tapestry of American history with our Springbok Puzzles - Americana 500 Piece Jigsaw Puzzle. Crafted in the USA, this large 18\" x 23.5\" puzzle is a testament to the art of traditional jigsaw puzzle-making.\\n\\n**Unique Cut Interlocking Pieces for a Challenging yet Rewarding Experience**\\n\\nEach piece of this puzzle is meticulously cut to fit together seamlessly, providing a satisfying challenge for puzzle enthusiasts of all levels. The unique cut interlocking pieces ensure a smooth and enjoyable assembly experience.\\n\\n**A Timeless Tribute to American Heritage**\\n\\nThis puzzle is more than just a game; it\\'s a tribute to the enduring spirit of America. With its vintage aesthetic and intricate design, it\\'s an ideal gift for history buffs, collectors, and anyone who appreciates the beauty of Americana.\\n\\n**Experience the Joy of Assembly and the Pride of Completion**\\n\\nAs you work on this puzzle, you\\'ll be transported to a bygone era, surrounded by the symbols and motifs that define American culture. The sense of accomplishment you\\'ll feel upon completion is unparalleled, making this puzzle a treasured keepsake for years to come.\\n\\n**A Quality Puzzle Crafted in the USA**\\n\\nSpringbok Puzzles is committed to quality and craftsmanship. Our Americana 500-Piece Jigsaw Puzzle is made'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03602f7401e74b0f8bb177a3167d724e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18b3b78c8d1948c7a34ac1a4212b8e87",
              "IPY_MODEL_cdef947871894923a7f4d0464e01079b",
              "IPY_MODEL_d4e7729fe36a461f802b32c329baea9f"
            ],
            "layout": "IPY_MODEL_10b8946335a54d728385ff5292d5e1a4"
          }
        },
        "0c74ef72161d4d24a22f4c1ce251c209": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10b8946335a54d728385ff5292d5e1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10de585a04494528b43d9e8a0fd88a22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b3b78c8d1948c7a34ac1a4212b8e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ba218e171844b6a8c83510d62d161ed",
            "placeholder": "​",
            "style": "IPY_MODEL_9743b2439cca4c5c834f367b03bcc1fe",
            "value": "Map: 100%"
          }
        },
        "3ecb30b81fde4093aa38669e76bbc022": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10de585a04494528b43d9e8a0fd88a22",
            "placeholder": "​",
            "style": "IPY_MODEL_8fd94f4811d54cd1a22c8d8a219360e0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "41d2e4cc549b498ca10558c05efb3479": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52021f0505494de7b4eeb04c0c314d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67ecbf442e3848919d5833bba8399cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ba218e171844b6a8c83510d62d161ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81aa9173adc74e289d8b32cabb93b3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81ff1f3c895d4f4db682490ad47f7cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f00fb44cfba84875a93213c8a8d95556",
            "placeholder": "​",
            "style": "IPY_MODEL_f5374a39cb784bda8cacbebfa8bdfd04",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "84b6782254a840b3b41fbe788990e128": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89301a8501a4449393e152705cf9e6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81ff1f3c895d4f4db682490ad47f7cb5",
              "IPY_MODEL_c0544f709a26484eb74b9f5bd4ccb24b",
              "IPY_MODEL_8f2adc73df734193bc43cf087c6d5a11"
            ],
            "layout": "IPY_MODEL_67ecbf442e3848919d5833bba8399cdd"
          }
        },
        "8f2adc73df734193bc43cf087c6d5a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41d2e4cc549b498ca10558c05efb3479",
            "placeholder": "​",
            "style": "IPY_MODEL_52021f0505494de7b4eeb04c0c314d46",
            "value": " 5/5 [00:08&lt;00:00,  1.48s/it]"
          }
        },
        "8fd94f4811d54cd1a22c8d8a219360e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9743b2439cca4c5c834f367b03bcc1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b0a64789798406fb07023011075468e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e0af3471f0d40b4a9f8ebcb47435b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ecb30b81fde4093aa38669e76bbc022",
              "IPY_MODEL_ced5b125d7054502b042ac2345110547",
              "IPY_MODEL_a7418715e53148cba2a5c871295ba3d8"
            ],
            "layout": "IPY_MODEL_a23e0c5078494bf7859287c52bca1cd0"
          }
        },
        "a23e0c5078494bf7859287c52bca1cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7418715e53148cba2a5c871295ba3d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c08d0b77704ac0b6019cf8f2438281",
            "placeholder": "​",
            "style": "IPY_MODEL_0c74ef72161d4d24a22f4c1ce251c209",
            "value": " 5/5 [00:05&lt;00:00,  1.46it/s]"
          }
        },
        "bf8248f1125f4bd19ffa0bebba00d24b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0544f709a26484eb74b9f5bd4ccb24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf8248f1125f4bd19ffa0bebba00d24b",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81aa9173adc74e289d8b32cabb93b3c0",
            "value": 5
          }
        },
        "c55b43df657c4d63abdeee1fed5d2e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c86df59720e64eec91d36da1497ed542": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdef947871894923a7f4d0464e01079b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84b6782254a840b3b41fbe788990e128",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b0a64789798406fb07023011075468e",
            "value": 150
          }
        },
        "ced5b125d7054502b042ac2345110547": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c86df59720e64eec91d36da1497ed542",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c55b43df657c4d63abdeee1fed5d2e60",
            "value": 5
          }
        },
        "d15c1993c827494091c8a767c7fc44a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4e7729fe36a461f802b32c329baea9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d15c1993c827494091c8a767c7fc44a2",
            "placeholder": "​",
            "style": "IPY_MODEL_eddd0b9ff2ca41ddb1b090fd5a61a3b5",
            "value": " 150/150 [00:00&lt;00:00, 2492.66 examples/s]"
          }
        },
        "eddd0b9ff2ca41ddb1b090fd5a61a3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f00fb44cfba84875a93213c8a8d95556": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5374a39cb784bda8cacbebfa8bdfd04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8c08d0b77704ac0b6019cf8f2438281": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
